{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Chris-Carvelli/ContinualLearning-ITU19/blob/master/Minigrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckgs5eqy8zLg",
    "colab_type": "text"
   },
   "source": [
    "# Minigird HyperNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "97gUL_Fy5ZDj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def random_z_v(z_dim, z_num):\n",
    "    # ret = np.random.normal(0.01, 1.0, z_dim * z_num)\n",
    "    return torch.distributions.normal.Normal(torch.zeros([z_dim * z_num]), 1.0).sample()\n",
    "\n",
    "\n",
    "def plot(env, experiment):\n",
    "    path = os.path.join(\n",
    "        os.getcwd(),\n",
    "        f'Experiments/{env}/{experiment}/process.pickle'\n",
    "    )\n",
    "\n",
    "    fp = open(path, 'rb')\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        data.append(pickle.load(fp))\n",
    "    except EOFError:\n",
    "        fp.close()\n",
    "\n",
    "    gen = list(range(len(data)))\n",
    "    s_med = [d[0] for d in data]\n",
    "    s_avg = [d[1] for d in data]\n",
    "    s_max = [d[2] for d in data]\n",
    "\n",
    "    plt.plot(gen, s_med)\n",
    "    plt.plot(gen, s_avg)\n",
    "    plt.plot(gen, s_max)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "slLxMUT75cip",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import gym\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# TODO create proper setting file (as .cfg)\n",
    "Z_DIM = 32\n",
    "Z_VECT_EVOLUTION_PROBABILITY = 0.5\n",
    "# TODO compute in HyperNN.__init__()\n",
    "Z_NUM = 4\n",
    "\n",
    "\n",
    "class HyperNN(nn.Module):\n",
    "    def __init__(self, named_parameters=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO examine shapes of all layers and get max\n",
    "        max_size = 32 * 64 * 2 * 2\n",
    "\n",
    "        # TODO get n layers from len(shapes)\n",
    "        self.z_v = random_z_v(Z_DIM, Z_NUM)\n",
    "\n",
    "        self.l1 = nn.Linear(Z_DIM, 128)\n",
    "        self.l2 = nn.Linear(128, 128)\n",
    "        self.out = nn.Linear(128, max_size)\n",
    "\n",
    "        self.add_tensors = {}\n",
    "\n",
    "        self.init()\n",
    "\n",
    "    def forward(self, layer_index):\n",
    "        x = chunks(self.z_v, Z_DIM)[layer_index]\n",
    "\n",
    "        # x = torch.from_numpy(x).float()\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "\n",
    "        return self.out(x)\n",
    "\n",
    "    def evolve(self, sigma):\n",
    "        p = torch.distributions.normal.Normal(0.5, 0.1).sample().item()\n",
    "        if p > Z_VECT_EVOLUTION_PROBABILITY:\n",
    "            # evolve z vector\n",
    "            self.z_v += torch.distributions.normal.Normal(torch.zeros([Z_DIM * Z_NUM]), sigma).sample()\n",
    "        else:\n",
    "            # evolve weights\n",
    "            params = self.named_parameters()\n",
    "            for name, tensor in sorted(params):\n",
    "                to_add = self.add_tensors[tensor.size()]\n",
    "                to_add.normal_(0.0, sigma)\n",
    "                tensor.data.add_(to_add)\n",
    "\n",
    "    def init(self):\n",
    "        for name, tensor in self.named_parameters():\n",
    "            if tensor.size() not in self.add_tensors:\n",
    "                self.add_tensors[tensor.size()] = torch.Tensor(tensor.size())\n",
    "            if 'weight' in name:\n",
    "                nn.init.kaiming_normal(tensor)\n",
    "            else:\n",
    "                tensor.data.zero_()\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hyperNN = HyperNN()\n",
    "\n",
    "        # Define image embedding\n",
    "        self.image_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 4)\n",
    "\n",
    "        self.add_tensors = {}\n",
    "\n",
    "        self.update_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.reshape([1, 147])\n",
    "        x = torch.transpose(torch.transpose(x, 1, 3), 2, 3)\n",
    "        x = self.image_conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        return self.out(x)\n",
    "\n",
    "    def evolve(self, sigma):\n",
    "        self.hyperNN.evolve(sigma)\n",
    "        self.update_weights()\n",
    "\n",
    "    def init(self):\n",
    "        for name, tensor in self.named_parameters():\n",
    "            if tensor.size() not in self.add_tensors:\n",
    "                self.add_tensors[tensor.size()] = torch.Tensor(tensor.size())\n",
    "            if 'weight' in name:\n",
    "                tensor.data.normal_(0, 1)\n",
    "                tensor.data *= 1 / torch.sqrt(tensor.pow(2).sum(1, keepdim=True))\n",
    "            else:\n",
    "                tensor.data.zero_()\n",
    "\n",
    "    def update_weights(self):\n",
    "        # TODO find better impl\n",
    "        z_chunk = 0\n",
    "        for i, layer in enumerate(self.image_conv):\n",
    "            for name, param in layer.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    self.image_conv[i].weight = self.get_weights(z_chunk, layer.weight.shape)\n",
    "                    z_chunk += 1\n",
    "\n",
    "    def get_weights(self, layer_index, layer_shape):\n",
    "        w = self.hyperNN(layer_index)\n",
    "        w = torch.narrow(w, 0, 0, reduce((lambda x, y: x * y), layer_shape))\n",
    "        w = w.view(layer_shape)\n",
    "\n",
    "        return torch.nn.Parameter(w)\n",
    "\n",
    "\n",
    "def evaluate_model(env_key, model, max_eval, render=False, fps=60):\n",
    "    env = gym.make(env_key)\n",
    "    # env = FlatObsWrapper(env)\n",
    "    state = env.reset()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tot_reward = 0\n",
    "    reward = 0\n",
    "    n_eval = 0\n",
    "    # TMP\n",
    "    action_freq = np.zeros([7])\n",
    "    while reward == 0 and n_eval < max_eval:\n",
    "        state = state['image']\n",
    "\n",
    "        # removed some scaffolding, check if something was needed\n",
    "        values = model(Variable(torch.Tensor([state])))\n",
    "        # values = env.step(env.action_space.sample())\n",
    "        action = np.argmax(values.data.numpy()[:env.action_space.n])\n",
    "\n",
    "        # TMP remapping toggle action\n",
    "        if action is 3:\n",
    "            action = 5\n",
    "\n",
    "        action_freq[action] += 1\n",
    "        state, reward, is_done, _ = env.step(action)\n",
    "        if render:\n",
    "            print('hello')\n",
    "            env.render('human')\n",
    "            print('action=%s, reward=%.2f' % (action, reward))\n",
    "            time.sleep(1/fps)\n",
    "\n",
    "        tot_reward += reward\n",
    "        n_eval += 1\n",
    "\n",
    "    env.close()\n",
    "    if tot_reward > 0:\n",
    "        print(f'action_freq: {action_freq/n_eval}\\treward: {tot_reward}')\n",
    "    return tot_reward\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    ret = []\n",
    "    for i in range(0, len(l), n):\n",
    "        ret.append(l[i:i + n])\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NJisme6b5fXb",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class GA:\n",
    "    def __init__(self, population, env_key, max_eval=100):\n",
    "        self.population = population\n",
    "        self.env_key = env_key\n",
    "        self.max_eval = max_eval\n",
    "\n",
    "        self.models = [Model() for _ in range(population)]\n",
    "\n",
    "    def get_best_models(self, models=None, trials=1):\n",
    "        if models is None:\n",
    "            models = self.models\n",
    "\n",
    "        scored_models = list(zip(\n",
    "            models,\n",
    "            map(\n",
    "                evaluate_model,\n",
    "                [self.env_key] * (self.population * trials),\n",
    "                [y for x in models for y in trials * [x]],\n",
    "                [self.max_eval] * (self.population * trials))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        scored_models = [(scored_models[i][0], sum(s for _, s in scored_models[i * trials:(i + 1)*trials]) / trials)\n",
    "                         for i in range(0, len(scored_models), trials)]\n",
    "        scored_models.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return scored_models\n",
    "\n",
    "    def evolve_iter(self, sigma, truncation, trials, elite_trials, n_elites):\n",
    "        scored_models = self.get_best_models(trials=trials)\n",
    "        models = [m for m, _ in scored_models]\n",
    "        scores = [s for _, s in scored_models]\n",
    "        median_score = np.median(scores)\n",
    "        mean_score = np.mean(scores)\n",
    "        max_score = scored_models[0][1]\n",
    "\n",
    "        scored_parents = self.get_best_models(models[:truncation], elite_trials)\n",
    "        parents = [p for p, _ in filter(lambda x: x[1] > 0, scored_parents)]\n",
    "        # Elitism\n",
    "        self.models = parents[:n_elites]\n",
    "\n",
    "        for individual in range(self.population - n_elites):\n",
    "            self.models.append(copy.deepcopy(random.choice(scored_models)[0]))\n",
    "            self.models[-1].evolve(sigma)\n",
    "\n",
    "        return median_score, mean_score, max_score, self.models[0]\n",
    "\n",
    "    def optimize(self, n_generation, sigma, truncation, trials=1, elite_trials=1, n_elites=1):\n",
    "        print('start')\n",
    "        path = os.path.join(\n",
    "            os.getcwd(),\n",
    "            'Experiments',\n",
    "            self.env_key,\n",
    "            f'{self.population}_{n_generation}_{sigma}_{truncation}')\n",
    "        os.makedirs(path)\n",
    "        fp = open(f'{path}\\\\process.pickle', 'ab')\n",
    "\n",
    "        for g in range(n_generation):\n",
    "            s_med, s_avg, s_max, elite = self.evolve_iter(sigma, truncation, trials, elite_trials, n_elites)\n",
    "\n",
    "            print(f'Done with generation {g} [Median: {s_med}, average: {s_avg}, max: {s_max}]')\n",
    "            pickle.dump((s_med, s_avg, s_max, elite), fp)\n",
    "\n",
    "        print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gOQ8NXEu5hpa",
    "colab_type": "code",
    "outputId": "5346e190-ca63-4d74-8ce2-6510a45d1326",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "action_freq: [0.23076923 0.         0.76923077 0.         0.         0.\n",
      " 0.        ]\treward: 0.954296875\n",
      "action_freq: [0.         0.28571429 0.71428571 0.         0.         0.\n",
      " 0.        ]\treward: 0.95078125\n",
      "action_freq: [0.         0.16666667 0.83333333 0.         0.         0.\n",
      " 0.        ]\treward: 0.97890625\n",
      "action_freq: [0.         0.09090909 0.90909091 0.         0.         0.\n",
      " 0.        ]\treward: 0.961328125\n",
      "action_freq: [0.        0.2173913 0.7826087 0.        0.        0.        0.       ]\treward: 0.919140625\n",
      "action_freq: [0.         0.11111111 0.88888889 0.         0.         0.\n",
      " 0.        ]\treward: 0.968359375\n",
      "action_freq: [0.         0.11111111 0.88888889 0.         0.         0.\n",
      " 0.        ]\treward: 0.968359375\n",
      "action_freq: [0.   0.25 0.75 0.   0.   0.   0.  ]\treward: 0.9296875\n",
      "action_freq: [0.        0.2173913 0.7826087 0.        0.        0.        0.       ]\treward: 0.919140625\n",
      "action_freq: [0.  0.2 0.8 0.  0.  0.  0. ]\treward: 0.982421875\n",
      "action_freq: [0.    0.125 0.875 0.    0.    0.    0.   ]\treward: 0.971875\n",
      "action_freq: [0.         0.11111111 0.88888889 0.         0.         0.\n",
      " 0.        ]\treward: 0.968359375\n",
      "action_freq: [0.  0.1 0.9 0.  0.  0.  0. ]\treward: 0.96484375\n",
      "action_freq: [0.3 0.  0.7 0.  0.  0.  0. ]\treward: 0.96484375\n",
      "action_freq: [0.25 0.   0.75 0.   0.   0.   0.  ]\treward: 0.9578125\n",
      "Done with generation 0 [Median: 0.0, average: 0.00576796875, max: 0.97890625]\n",
      "action_freq: [0.4 0.  0.6 0.  0.  0.  0. ]\treward: 0.96484375\n"
     ]
    }
   ],
   "source": [
    "import gym_minigrid\n",
    "\n",
    "def main():\n",
    "    print('main')\n",
    "\n",
    "    ga = GA(500, 'MiniGrid-Empty-Noise-8x8-v0')\n",
    "\n",
    "    ga.optimize(50, 0.005, 20, elite_trials=10, n_elites=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Minigrid",
   "version": "0.3.2",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
